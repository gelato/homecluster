apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    service: llama-gpt-api
  name: llama-gpt-api
spec:
  replicas: 1
  selector:
    matchLabels:
      service: llama-gpt-api
  template:
    metadata:
      labels:
        service: llama-gpt-api
    spec:
      runtimeClassName: nvidia
      containers:
        - name: llama-gpt-api
          image: ghcr.io/getumbrel/llama-gpt-api:1.0.1
          command: ["run.sh"]
          args: ["--with-cuda"]
          env:
            - name: MODEL
              valueFrom: 
                configMapKeyRef:
                  name: llama-gpt
                  key: DEFAULT_MODEL
          resources:
            requests:
              memory: 15Gi
            limits:
              nvidia.com/gpu: 1
      restartPolicy: Always